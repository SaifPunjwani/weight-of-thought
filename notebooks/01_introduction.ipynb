{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Weight-of-Thought\n",
    "\n",
    "This notebook introduces the Weight-of-Thought (WoT) neural reasoning framework, a novel approach extending beyond traditional Chain-of-Thought reasoning by representing reasoning as an interconnected graph of nodes rather than a linear sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make sure the weight-of-thought package is in the Python path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import WoT components\n",
    "from wot.models import WOTReasoner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Weight-of-Thought Architecture\n",
    "\n",
    "Weight-of-Thought is composed of several key components:\n",
    "\n",
    "1. **Language Encoder**: Processes input text using a transformer-based model\n",
    "2. **Node Network**: A set of specialized nodes that process and exchange information\n",
    "3. **Message Passing System**: Allows nodes to share information through weighted connections\n",
    "4. **Reasoning Steps**: Sequential reasoning layers that refine the reasoning representation\n",
    "5. **Task-Specific Output Heads**: Specialized outputs for different reasoning tasks\n",
    "\n",
    "Let's visualize the architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple visualization of the WoT architecture\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes\n",
    "input_node = \"Input Text\"\n",
    "encoder_node = \"Language Encoder\"\n",
    "reasoning_nodes = [f\"Node {i+1}\" for i in range(8)]\n",
    "reasoning_steps = [f\"Reasoning Step {i+1}\" for i in range(4)]\n",
    "output_node = \"Task-Specific Output\"\n",
    "\n",
    "G.add_node(input_node, pos=(0, 0.5))\n",
    "G.add_node(encoder_node, pos=(0.2, 0.5))\n",
    "\n",
    "# Position reasoning nodes in a circle\n",
    "node_radius = 0.3\n",
    "node_center = (0.5, 0.5)\n",
    "for i, node in enumerate(reasoning_nodes):\n",
    "    angle = 2 * np.pi * i / len(reasoning_nodes)\n",
    "    x = node_center[0] + node_radius * np.cos(angle)\n",
    "    y = node_center[1] + node_radius * np.sin(angle)\n",
    "    G.add_node(node, pos=(x, y))\n",
    "\n",
    "# Position reasoning steps in a sequence\n",
    "for i, step in enumerate(reasoning_steps):\n",
    "    G.add_node(step, pos=(0.8 + i * 0.05, 0.5))\n",
    "\n",
    "G.add_node(output_node, pos=(1.0, 0.5))\n",
    "\n",
    "# Add edges\n",
    "G.add_edge(input_node, encoder_node)\n",
    "G.add_edge(encoder_node, reasoning_nodes[0])\n",
    "\n",
    "# Connect reasoning nodes (fully connected)\n",
    "for i, source in enumerate(reasoning_nodes):\n",
    "    for j, target in enumerate(reasoning_nodes):\n",
    "        if i != j:  # No self-loops\n",
    "            G.add_edge(source, target, weight=np.random.uniform(0.1, 1.0))\n",
    "\n",
    "# Connect last node to first reasoning step\n",
    "G.add_edge(reasoning_nodes[-1], reasoning_steps[0])\n",
    "\n",
    "# Connect reasoning steps in sequence\n",
    "for i in range(len(reasoning_steps) - 1):\n",
    "    G.add_edge(reasoning_steps[i], reasoning_steps[i+1])\n",
    "\n",
    "# Connect last reasoning step to output\n",
    "G.add_edge(reasoning_steps[-1], output_node)\n",
    "\n",
    "# Draw the network\n",
    "pos = nx.get_node_attributes(G, 'pos')\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Draw different node groups with different colors\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=[input_node], node_color='lightblue', node_size=2000, alpha=0.8)\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=[encoder_node], node_color='lightgreen', node_size=2000, alpha=0.8)\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=reasoning_nodes, node_color='salmon', node_size=1500, alpha=0.8)\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=reasoning_steps, node_color='lightgray', node_size=1500, alpha=0.8)\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=[output_node], node_color='gold', node_size=2000, alpha=0.8)\n",
    "\n",
    "# Draw edges with varying width based on weight\n",
    "edge_weights = [G[u][v].get('weight', 0.5) for u, v in G.edges()]\n",
    "nx.draw_networkx_edges(G, pos, width=edge_weights, alpha=0.6, arrowsize=10, arrowstyle='->')\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_family='sans-serif')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title('Weight-of-Thought Architecture', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Pre-trained Model\n",
    "\n",
    "Let's load a pre-trained WoT model and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a WOT reasoner\n",
    "wot_reasoner = WOTReasoner()\n",
    "\n",
    "# Load pre-trained model if available\n",
    "model_path = '../results/models/wot_model_final.pt'\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Loading pre-trained model from {model_path}\")\n",
    "    wot_reasoner.load_model(model_path)\n",
    "else:\n",
    "    print(\"No pre-trained model found. Using a new model.\")\n",
    "\n",
    "# Print model information\n",
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"Hidden dimension: {wot_reasoner.wot_model.hidden_dim}\")\n",
    "print(f\"Number of nodes: {wot_reasoner.wot_model.num_nodes}\")\n",
    "print(f\"Number of reasoning steps: {wot_reasoner.wot_model.num_reasoning_steps}\")\n",
    "print(f\"Device: {wot_reasoner.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasoning Tasks\n",
    "\n",
    "The WoT model can handle various reasoning tasks. Let's see some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example reasoning tasks\n",
    "examples = [\n",
    "    {\n",
    "        'question': 'If all Bloops are Razzies and all Razzies are Wazzies, are all Bloops definitely Wazzies? Answer with Yes or No.',\n",
    "        'type': 'syllogism',\n",
    "        'answer': 'Yes',\n",
    "        'description': 'Syllogistic reasoning with transitive property'\n",
    "    },\n",
    "    {\n",
    "        'question': 'What is the next number in the sequence: 2, 4, 6, 8, 10, ...?',\n",
    "        'type': 'math_sequence',\n",
    "        'answer': '12',\n",
    "        'description': 'Pattern recognition in arithmetic sequence'\n",
    "    },\n",
    "    {\n",
    "        'question': 'John has 3 times as many apples as Mary. Together, they have 40 apples. How many apples does John have?',\n",
    "        'type': 'algebra',\n",
    "        'answer': '30',\n",
    "        'description': 'Algebraic word problem with ratio'\n",
    "    },\n",
    "    {\n",
    "        'question': 'In a room of 5 people, everyone shakes hands with everyone else exactly once. How many handshakes are there in total?',\n",
    "        'type': 'combinatorics',\n",
    "        'answer': '10',\n",
    "        'description': 'Combinatorial counting problem'\n",
    "    },\n",
    "    {\n",
    "        'question': 'Is every square a rectangle? Answer with Yes or No.',\n",
    "        'type': 'geometry',\n",
    "        'answer': 'Yes',\n",
    "        'description': 'Geometric properties and classification'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run inference on each example\n",
    "for i, example in enumerate(examples):\n",
    "    question = example['question']\n",
    "    task_type = example['type']\n",
    "    true_answer = example['answer']\n",
    "    \n",
    "    print(f\"\\nExample {i+1}: {example['description']}\")\n",
    "    print(f\"Task Type: {task_type}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"True Answer: {true_answer}\")\n",
    "    \n",
    "    # Run inference\n",
    "    predicted_answer = wot_reasoner.infer(question, task_type)\n",
    "    print(f\"Predicted Answer: {predicted_answer}\")\n",
    "    print(f\"Correct: {str(true_answer) == predicted_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Reasoning Process\n",
    "\n",
    "One of the key advantages of the WoT architecture is its interpretability. Let's visualize the reasoning process for one of our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an example for visualization\n",
    "vis_example = examples[0]  # Syllogism example\n",
    "question = vis_example['question']\n",
    "task_type = vis_example['type']\n",
    "\n",
    "# Run inference to populate attention weights\n",
    "_ = wot_reasoner.infer(question, task_type)\n",
    "\n",
    "# Create a visualization figure\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "gs = plt.GridSpec(2, 2, figure=fig)\n",
    "\n",
    "# 1. Node Attention Weights\n",
    "if hasattr(wot_reasoner.wot_model, 'node_attention_weights') and wot_reasoner.wot_model.node_attention_weights is not None:\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    node_attention = wot_reasoner.wot_model.node_attention_weights.numpy()\n",
    "    \n",
    "    # Plot as bar chart\n",
    "    ax1.bar(range(wot_reasoner.wot_model.num_nodes), node_attention.squeeze())\n",
    "    ax1.set_xlabel('Node Index')\n",
    "    ax1.set_ylabel('Attention Weight')\n",
    "    ax1.set_title('Node Attention Weights')\n",
    "\n",
    "# 2. Reasoning Step Attention Weights\n",
    "if hasattr(wot_reasoner.wot_model, 'reasoning_attention_weights') and wot_reasoner.wot_model.reasoning_attention_weights is not None:\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    reasoning_attention = wot_reasoner.wot_model.reasoning_attention_weights.numpy()\n",
    "    \n",
    "    # Plot as bar chart\n",
    "    ax2.bar(range(wot_reasoner.wot_model.num_reasoning_steps), reasoning_attention.squeeze())\n",
    "    ax2.set_xlabel('Reasoning Step')\n",
    "    ax2.set_ylabel('Attention Weight')\n",
    "    ax2.set_title('Reasoning Step Attention Weights')\n",
    "\n",
    "# 3. Edge Attention Matrix\n",
    "if hasattr(wot_reasoner.wot_model, 'edge_matrices') and wot_reasoner.wot_model.edge_matrices is not None:\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    # Get the edge matrix from the last message passing iteration\n",
    "    edge_matrix = wot_reasoner.wot_model.edge_matrices[-1].detach().cpu().numpy()\n",
    "    \n",
    "    # Average across batch dimension if needed\n",
    "    if len(edge_matrix.shape) > 2:\n",
    "        edge_matrix = np.mean(edge_matrix, axis=0)\n",
    "    \n",
    "    # Plot as heatmap\n",
    "    sns.heatmap(edge_matrix, annot=True, fmt='.2f', cmap='viridis', ax=ax3)\n",
    "    ax3.set_xlabel('To Node')\n",
    "    ax3.set_ylabel('From Node')\n",
    "    ax3.set_title('Edge Attention Matrix')\n",
    "\n",
    "# 4. Graph Visualization\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes\n",
    "for i in range(wot_reasoner.wot_model.num_nodes):\n",
    "    G.add_node(i)\n",
    "\n",
    "# Add edges with weights > threshold from the edge matrix\n",
    "if hasattr(wot_reasoner.wot_model, 'edge_matrices') and wot_reasoner.wot_model.edge_matrices is not None:\n",
    "    edge_matrix = wot_reasoner.wot_model.edge_matrices[-1].detach().cpu().numpy()\n",
    "    if len(edge_matrix.shape) > 2:\n",
    "        edge_matrix = np.mean(edge_matrix, axis=0)\n",
    "    \n",
    "    threshold = 0.1\n",
    "    for i in range(wot_reasoner.wot_model.num_nodes):\n",
    "        for j in range(wot_reasoner.wot_model.num_nodes):\n",
    "            if i != j and edge_matrix[i, j] > threshold:\n",
    "                G.add_edge(i, j, weight=edge_matrix[i, j])\n",
    "\n",
    "# Get node sizes based on node attention\n",
    "if hasattr(wot_reasoner.wot_model, 'node_attention_weights') and wot_reasoner.wot_model.node_attention_weights is not None:\n",
    "    node_attention = wot_reasoner.wot_model.node_attention_weights.numpy()\n",
    "    node_sizes = node_attention.squeeze() * 1000  # Scale for visualization\n",
    "else:\n",
    "    node_sizes = [300] * wot_reasoner.wot_model.num_nodes\n",
    "\n",
    "# Get edge weights\n",
    "edge_weights = [G[u][v]['weight'] * 2 for u, v in G.edges()]\n",
    "\n",
    "# Draw the network\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='skyblue', alpha=0.8, ax=ax4)\n",
    "nx.draw_networkx_labels(G, pos, ax=ax4)\n",
    "nx.draw_networkx_edges(G, pos, width=edge_weights, alpha=0.5, edge_color='gray', \n",
    "                       connectionstyle='arc3,rad=0.1', arrowsize=15, ax=ax4)\n",
    "\n",
    "ax4.set_title('Reasoning Network for Syllogism Task')\n",
    "ax4.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'Weight-of-Thought Reasoning Analysis for: \"{question}\"', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Weight-of-Thought architecture offers several advantages over traditional Chain-of-Thought reasoning:\n",
    "\n",
    "1. **Beyond sequential reasoning**: Represents reasoning as an interconnected graph rather than a linear chain\n",
    "2. **Parallel processing**: Different aspects of reasoning can be processed simultaneously by different nodes\n",
    "3. **Adaptive information flow**: Dynamic attention mechanisms focus on the most relevant connections\n",
    "4. **Interpretability**: The network structure provides insights into the reasoning process\n",
    "5. **Task specialization**: Different nodes can specialize for different types of reasoning tasks\n",
    "\n",
    "In the next notebook, we'll explore how to train a WoT model on custom reasoning tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
